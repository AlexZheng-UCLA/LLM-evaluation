{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72809e2b8b134d0e8549645d11517d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9169134bba524e90b243e0dc0077d4e6",
              "IPY_MODEL_fa10813282fa40afa8650480a3ae0dd7",
              "IPY_MODEL_9ffcb3e80f81417fb4880f9529890e33"
            ],
            "layout": "IPY_MODEL_c8cac661c90e4728aee065b6ec83e047"
          }
        },
        "9169134bba524e90b243e0dc0077d4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b51139968d8246b783adc6e7209a0301",
            "placeholder": "​",
            "style": "IPY_MODEL_693d41508ab54974b97263cd877be9a9",
            "value": "  0%"
          }
        },
        "fa10813282fa40afa8650480a3ae0dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f73646051d04e6ea2e43d6ceb176bac",
            "max": 65160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c43967e3f28e4b38945fdcf950870c60",
            "value": 0
          }
        },
        "9ffcb3e80f81417fb4880f9529890e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3ebbbd4b3b94b70b81198721a95687b",
            "placeholder": "​",
            "style": "IPY_MODEL_932f6609c8bb478a8043d4623718daf2",
            "value": " 0/65160 [00:00&lt;?, ?it/s]"
          }
        },
        "c8cac661c90e4728aee065b6ec83e047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b51139968d8246b783adc6e7209a0301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "693d41508ab54974b97263cd877be9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f73646051d04e6ea2e43d6ceb176bac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43967e3f28e4b38945fdcf950870c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3ebbbd4b3b94b70b81198721a95687b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "932f6609c8bb478a8043d4623718daf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlEBfNdQoCS4",
        "outputId": "44cbde4a-ce5a-4095-b249-0ba67c13cb14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LLM-evaluation' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AlexZheng-UCLA/LLM-evaluation.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd LLM-evaluation\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lov8AuibosAv",
        "outputId": "1e23ae38-f9e9-4dfa-e5af-913029e2739e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLM-evaluation\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.65.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.4.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.29.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.19.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.12.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 2)) (2022.7.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate->-r requirements.txt (line 4)) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate->-r requirements.txt (line 4)) (2.27.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate->-r requirements.txt (line 4)) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate->-r requirements.txt (line 4)) (2023.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate->-r requirements.txt (line 4)) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate->-r requirements.txt (line 4)) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate->-r requirements.txt (line 4)) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 6)) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 6)) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 6)) (0.13.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 7)) (2.0.1+cu118)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (0.40.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 4)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 4)) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 4)) (3.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate->-r requirements.txt (line 7)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate->-r requirements.txt (line 7)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate->-r requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate->-r requirements.txt (line 7)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate->-r requirements.txt (line 7)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate->-r requirements.txt (line 7)) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 8)) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 8)) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate->-r requirements.txt (line 7)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from tqdm.auto import tqdm\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "metadata": {
        "id": "jR6bYZjko57v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSdn_pVMk_Ec",
        "outputId": "7f78e179-3369-43f6-feb9-23333f576908"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model and Tokenizer"
      ],
      "metadata": {
        "id": "n19dByV8pT6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model and tokenizer\n",
        "model_name = \"OpenAssistant/reward-model-deberta-v3-base\"\n",
        "model, tokenizer = AutoModelForSequenceClassification.from_pretrained(model_name), AutoTokenizer.from_pretrained(model_name)\n",
        "question, answer = \"Explain nuclear fusion like I am five\", \"Nuclear fusion is the process by which two or more protons and neutrons combine to form a single nucleus. It is a very important process in the universe, as it is the source of energy for stars and galaxies. Nuclear fusion is also a key process in the production of energy for nuclear power plants.\"\n",
        "inputs = tokenizer(question, answer, return_tensors='pt')\n",
        "score = model(**inputs).logits[0].cpu().detach()\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gfy0TT0pGpE",
        "outputId": "98ef4278-5116-4e99-800e-7b58729f3718"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5816])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and Dataloader"
      ],
      "metadata": {
        "id": "dDJLCNewpZSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset \n",
        "class OasstDataset(Dataset):\n",
        "    def __init__(self, filename, tokenizer):\n",
        "        self.data = pd.read_csv(filename)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        text1, text2, label = row['prompt_text'], row['answer_text'], row['quality']\n",
        "        inputs = self.tokenizer(text1, text2, padding='max_length', max_length=512, truncation=True)\n",
        "        inputs = {key: torch.tensor(val) for key, val in inputs.items()}  # Convert lists to tensors\n",
        "        inputs['labels'] = torch.tensor(label).unsqueeze(0).float()\n",
        "        return inputs\n",
        "\n",
        "# Create Dataloader\n",
        "train_dataset_full = OasstDataset('dataset/oasst1_quality_train.csv', tokenizer)\n",
        "eval_dataset_full = OasstDataset('dataset/oasst1_quality_val.csv', tokenizer)\n",
        "print(f\"train_dataset size: {len(train_dataset_full)}\")\n",
        "print(f\"eval_dataset size: {len(eval_dataset_full)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFBQVYmppfip",
        "outputId": "79fbbc61-839e-48ec-9ef7-c6866a4035b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset size: 52127\n",
            "eval_dataset size: 2745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "train_indices = random.sample(range(len(train_dataset_full)), 1000)\n",
        "train_dataset_small = Subset(train_dataset_full, train_indices)\n",
        "train_indices = random.sample(range(len(train_dataset_full)), 5000)\n",
        "train_dataset_medium = Subset(train_dataset_full, train_indices)"
      ],
      "metadata": {
        "id": "95iad_X9pyoP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Config"
      ],
      "metadata": {
        "id": "KEBxujHHtD7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Config\n",
        "batch_size = 8\n",
        "train_dataloader = DataLoader(train_dataset_full, shuffle=True, batch_size=batch_size)\n",
        "path_to_save_model = \"LLM_evaluator_full_dataset\"\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_epochs = 10\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "# Create a summary writer\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "id": "KLVMTODgqQMw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluating"
      ],
      "metadata": {
        "id": "Qv_nJ2cmt7jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=2, delta=0, path='checkpoint.pt'):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_score, model):\n",
        "\n",
        "        score = val_score\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(score, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.save_checkpoint(score, model)\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_score, model):\n",
        "      model.save_pretrained(path_to_save_model)\n",
        "      print(f'Validation loss decreased ({self.best_score:.6f} --> {val_score:.6f}).  Saving model ...')\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(patience=2, delta=0.0001)"
      ],
      "metadata": {
        "id": "R1s7Bj5LA6Jg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar = tqdm(range(num_training_steps))\n",
        "model.train()\n",
        "\n",
        "# Store all loss and accuracy values\n",
        "loss_values = []\n",
        "accuracy_values = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss_values.append(loss.item())  # record the loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        # Write loss to TensorBoard for every step\n",
        "        writer.add_scalar('Loss/train', loss, epoch*len(train_dataloader)+i)\n",
        "\n",
        "    # Calculate and print mean loss\n",
        "    mean_loss = sum(loss_values) / len(loss_values)\n",
        "    print(f'Mean loss at epoch {epoch}: {mean_loss}')\n",
        "    loss_values = []  # Reset for the next epoch\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "\n",
        "    # Create a random subset of 100 samples from the evaluation dataset\n",
        "    eval_subset_indices = random.sample(range(len(eval_dataset_full)), 100)\n",
        "    eval_subset = Subset(eval_dataset_full, eval_subset_indices)\n",
        "    eval_dataloader_subset = DataLoader(eval_subset, batch_size=batch_size)\n",
        "\n",
        "    for i, batch in enumerate(eval_dataloader_subset):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "          outputs = model(**batch)\n",
        "\n",
        "        predictions = outputs.logits.squeeze().cpu().numpy()\n",
        "        labels = batch[\"labels\"].cpu().numpy()\n",
        "        mae = mean_absolute_error(labels, predictions)\n",
        "\n",
        "        accuracy_values.append(mae)\n",
        "\n",
        "        # Write accuracy to TensorBoard for every step\n",
        "        writer.add_scalar('Accuracy/val', mae, epoch*len(eval_dataloader_subset)+i)\n",
        "\n",
        "    # Calculate and print mean accuracy\n",
        "    mean_accuracy = sum(accuracy_values) / len(accuracy_values)\n",
        "    print(f'Mean Abosulute Error at epoch {epoch}: {mean_accuracy}')\n",
        "    accuracy_values = []  # Reset for the next epoch\n",
        "\n",
        "    # early stopping\n",
        "    early_stopping(mean_accuracy, model)\n",
        "    if early_stopping.early_stop:\n",
        "      print(f\"Early stopping at epoch -- {epoch}\")\n",
        "      tokenizer.save_pretrained(path_to_save_model)\n",
        "      break\n",
        "    # Switch back to training mode\n",
        "    model.train()\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "72809e2b8b134d0e8549645d11517d8e",
            "9169134bba524e90b243e0dc0077d4e6",
            "fa10813282fa40afa8650480a3ae0dd7",
            "9ffcb3e80f81417fb4880f9529890e33",
            "c8cac661c90e4728aee065b6ec83e047",
            "b51139968d8246b783adc6e7209a0301",
            "693d41508ab54974b97263cd877be9a9",
            "1f73646051d04e6ea2e43d6ceb176bac",
            "c43967e3f28e4b38945fdcf950870c60",
            "c3ebbbd4b3b94b70b81198721a95687b",
            "932f6609c8bb478a8043d4623718daf2"
          ]
        },
        "id": "YxJwj_lPs-Mm",
        "outputId": "231c42cb-9b60-415e-f711-b92f8b93c27a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/65160 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72809e2b8b134d0e8549645d11517d8e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "all_dirs = glob.glob(os.path.join(\"runs\", \"*\"))\n",
        "\n",
        "# Sort the directories based on modification time (most recent first)\n",
        "sorted_dirs = sorted(all_dirs, key=os.path.getmtime, reverse=True)\n",
        "newest_logdir = sorted_dirs[0]\n",
        "print(newest_logdir)\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir newest_logdir"
      ],
      "metadata": {
        "id": "_B0QFwAKv4cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save to google drive"
      ],
      "metadata": {
        "id": "lerOY50ccxrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "des_dir = f\"/content/gdrive/Shareddrives/CS_263_Shared\"\n",
        "if not os.path.exists(des_dir):\n",
        "  os.mkdir(des_dir)\n",
        "!cp -r /content/LLM-evaluation/{path_to_save_model} {des_dir}"
      ],
      "metadata": {
        "id": "bUThSTTecfgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quick examination"
      ],
      "metadata": {
        "id": "UNq8s950AHG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")\n",
        "question, answer = \"Explain nuclear fusion like I am five\", \"Nuclear fusion is the process by which two or more protons and neutrons combine to form a single nucleus. It is a very important process in the universe, as it is the source of energy for stars and galaxies. Nuclear fusion is also a key process in the production of energy for nuclear power plants.\"\n",
        "inputs = tokenizer(question, answer, return_tensors='pt')\n",
        "score = model(**inputs).logits[0].cpu().detach()\n",
        "print(score)"
      ],
      "metadata": {
        "id": "UqkVGrpBACfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "Grge7NKzic7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "class OasstDataset(Dataset):\n",
        "    def __init__(self, filename, tokenizer):\n",
        "        self.data = pd.read_csv(filename)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        text1, text2, label = row['prompt_text'], row['answer_text'], row['quality']\n",
        "        inputs = self.tokenizer(text1, text2, padding='max_length', max_length=512, truncation=True)\n",
        "        inputs = {key: torch.tensor(val) for key, val in inputs.items()}  # Convert lists to tensors\n",
        "        inputs['labels'] = torch.tensor(label).unsqueeze(0).float()\n",
        "        return inputs\n",
        "\n",
        "model_name = \"/content/gdrive/Shareddrives/CS_263_Shared/LLM_evaluator_small_dataset\"\n",
        "model, tokenizer = AutoModelForSequenceClassification.from_pretrained(model_name), AutoTokenizer.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Create Dataloader\n",
        "test_dataset_full = OasstDataset('/content/LLM-evaluation/dataset/oasst1_quality_val.csv', tokenizer)\n",
        "test_dataloader = DataLoader(test_dataset_full, batch_size=8, shuffle=False)\n",
        "\n",
        "# Save outputs to a list\n",
        "predictions_list = []\n",
        "\n",
        "# Iterate over batches\n",
        "for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
        "    # Send batch to device\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    # Calculate outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "        predictions = outputs.logits[0].cpu().numpy()\n",
        "        predictions_list.append(predictions)\n"
      ],
      "metadata": {
        "id": "a3VLAWc5TIoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions_list)"
      ],
      "metadata": {
        "id": "aSHPLlj8cR-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload to hugging face"
      ],
      "metadata": {
        "id": "myDxCvP7FOaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "SkebgV1N3lT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli repo create {path_to_save_model}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joL7FYkpFosH",
        "outputId": "9944bf80-7f33-4d50-a30d-9b37838b3843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90mgit version 2.25.1\u001b[0m\n",
            "\u001b[90mgit-lfs/2.9.2 (GitHub; linux amd64; go 1.13.5)\u001b[0m\n",
            "\n",
            "You are about to create \u001b[1mAlexZheng/LLM_evaluator_medium_dataset\u001b[0m\n",
            "Proceed? [Y/n] "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"AlexZheng-UCLA@gmail.com\"\n",
        "!git config --global user.name \"AlexZheng-UCLA\""
      ],
      "metadata": {
        "id": "29c3Y2IYP6Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {path_to_save_model}\n",
        "\n",
        "# Initialize a git repository in this directory\n",
        "!git init\n",
        "\n",
        "# Add the model and tokenizer files to the git repository\n",
        "!git add .\n",
        "\n",
        "# Commit the changes\n",
        "!git commit -m \"Initial commit\"\n",
        "\n",
        "# Push the model and tokenizer to the Hugging Face's Model Hub\n",
        "!git push https://huggingface.co/AlexZheng/{path_to_save_model}"
      ],
      "metadata": {
        "id": "yQN_CkCrLYLL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}